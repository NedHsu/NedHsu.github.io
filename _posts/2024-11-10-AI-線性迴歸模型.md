---
title: AI 第10天：線性迴歸模型
date: 2024-11-10 19:00:00 +0800
categories: [Software, AI]
tags: [AI, Python] 
math: true
excerpt: "線性迴歸是機器學習中最基礎的監督學習方法之一，廣泛用於處理迴歸問題（即預測連續值的問題）。今天，我們將學習線性迴歸的基本概念、數學原理、如何在 Python 中實現，以及它的應用與局限性。"
---

線性迴歸是機器學習中最基礎的監督學習方法之一，廣泛用於處理迴歸問題（即預測連續值的問題）。今天，我們將學習線性迴歸的基本概念、數學原理、如何在 Python 中實現，以及它的應用與局限性。

---

## **課程目標**
1. 了解線性迴歸的基本概念與數學基礎。  
2. 學會使用 Scikit-learn 建立和評估線性迴歸模型。  
3. 探索線性迴歸的實際應用場景與潛在局限性。

---

## **課程內容**

### **1. 線性迴歸的基本概念**

#### **1.1 什麼是線性迴歸？**  
線性迴歸的目的是學習一條直線，使得輸入變數 \( X \) 和目標變數 \( y \) 的關係能夠通過以下公式來描述：  
$$y = wX + b$$
其中：  
- \( w \)：係數（權重），表示輸入特徵對輸出的影響。  
- \( b \)：截距，用於調整直線的位置。  

#### **1.2 最小二乘法**
為了找到最佳的 \( w \) 和 \( b \)，我們通過最小化預測值與實際值之間的誤差平方和來優化模型：  
$$\text{損失函數} = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$

---

### **2. 實現單變數線性迴歸**

我們將從一個簡單的單變數線性迴歸範例開始。

#### **2.1 實作：單變數數據建模**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 模擬數據
X = np.array([[1], [2], [3], [4], [5]])  # 輸入變數
y = np.array([2, 4, 5, 4, 5])           # 目標變數

# 建立線性迴歸模型
model = LinearRegression()
model.fit(X, y)

# 預測
y_pred = model.predict(X)

# 繪製數據點與迴歸線
plt.scatter(X, y, color='blue', label='實際數據')
plt.plot(X, y_pred, color='red', label='預測線')
plt.title("單變數線性迴歸")
plt.xlabel("輸入變數 X")
plt.ylabel("目標變數 y")
plt.legend()
plt.show()

# 打印係數與截距
print(f"係數 (w): {model.coef_[0]:.2f}, 截距 (b): {model.intercept_:.2f}")
```

---

### **3. 多變數線性迴歸**

當我們有多個特徵（輸入變數）時，線性迴歸模型的公式為：  
$$y = w_1x_1 + w_2x_2 + ... + w_nx_n + b$$

#### **3.1 實作：多變數數據建模**

```python
from sklearn.datasets import make_regression

# 模擬多變數數據
X, y = make_regression(n_samples=100, n_features=2, noise=10, random_state=42)

# 建立線性迴歸模型
model = LinearRegression()
model.fit(X, y)

# 預測
y_pred = model.predict(X)

# 打印模型參數
print(f"係數: {model.coef_}, 截距: {model.intercept_}")
```

---

### **4. 評估線性迴歸模型**

#### **4.1 評估指標**  
1. **均方誤差（MSE）：** 測量預測值與實際值之間的平均平方誤差。  
   $$   MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
   \]
2. **決定係數（\( R^2 \)）：** 衡量模型對數據的解釋能力，範圍為 0 到 1，越接近 1 越好。

#### **4.2 實作：評估模型**

```python
from sklearn.metrics import mean_squared_error, r2_score

# 計算 MSE 與 R^2
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"均方誤差 (MSE): {mse:.2f}")
print(f"決定係數 (R^2): {r2:.2f}")
```

---

### **5. 線性迴歸的應用場景與局限性**

#### **5.1 應用場景**
- 預測房價（基於面積、地段等）。  
- 分析廣告支出與銷售額之間的關係。  
- 預測氣溫或經濟指標。  

#### **5.2 局限性**
1. **線性假設：** 線性迴歸假設特徵與目標變數之間存在線性關係，若不成立可能導致預測不準。  
2. **對異常值敏感：** 線性迴歸對異常值非常敏感，可能影響模型的穩定性。  
3. **多重共線性問題：** 當特徵之間高度相關時，模型可能變得不穩定。  

---

## **課後作業**
1. 搜集一組公開數據（例如 Kaggle 或 UCI Repository），使用單變數或多變數線性迴歸模型進行預測，並計算模型的 \( MSE \) 與 \( R^2 \)。  
2. 嘗試增加多個特徵，觀察模型性能是否提升。  
3. 思考與回答：  
   - 在什麼情況下線性迴歸無法良好表現？  
   - 如何處理異常值對模型的影響？
