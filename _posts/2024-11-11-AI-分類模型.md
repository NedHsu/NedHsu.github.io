---
title: AI 第11天：分類模型（KNN、SVM）
date: 2024-11-11 19:00:00 +0800
categories: [Software, AI]
tags: [AI, Python] 
excerpt: "分類模型是機器學習中用於處理分類問題的重要工具，今天我們將學習**最近鄰居法（K-Nearest Neighbors, KNN）**和**支持向量機（Support Vector Machine, SVM）**這兩種常見的分類方法。"
---

分類模型是機器學習中用於處理分類問題的重要工具，今天我們將學習**最近鄰居法（K-Nearest Neighbors, KNN）**和**支持向量機（Support Vector Machine, SVM）**這兩種常見的分類方法。

---

## **課程目標**
1. 了解 KNN 和 SVM 的基本概念與工作原理。  
2. 學習如何使用 Scikit-learn 實現 KNN 和 SVM。  
3. 比較兩種模型的特性與應用場景。

---

## **課程內容**

### **1. 最近鄰居法（KNN）**

#### **1.1 核心概念**  
KNN 是一種基於距離的非參數分類方法，通過計算樣本點與所有已知數據點的距離，選擇距離最近的 \( k \) 個鄰居進行投票來決定分類。

#### **1.2 步驟**  
1. 設定鄰居數 \( k \)。  
2. 計算待分類樣本與訓練數據集所有點的距離（例如歐幾里得距離）。  
3. 選擇最近的 \( k \) 個鄰居，根據它們的分類進行投票，票數最多的類別即為預測結果。

#### **1.3 實作範例：使用 KNN 進行分類**

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 載入 Iris 數據集
iris = load_iris()
X, y = iris.data, iris.target

# 分割訓練與測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 建立 KNN 模型
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# 預測與評估
y_pred = knn.predict(X_test)
print(f"KNN 模型準確率: {accuracy_score(y_test, y_pred):.2f}")
```

---

### **2. 支持向量機（SVM）**

#### **2.1 核心概念**  
SVM 是一種強大的分類模型，其核心思想是尋找一條最佳超平面來分隔不同類別的數據。SVM 的關鍵目標是最大化分類邊界的間隔。

#### **2.2 特點**  
1. 能處理高維數據且具備良好的泛化能力。  
2. 可以通過核函數（Kernel Function）處理非線性分類問題。  

#### **2.3 核函數的種類**  
1. 線性核：適合線性可分的數據。  
2. 多項式核：擴展數據至多項式空間。  
3. 徑向基核（RBF）：廣泛用於處理非線性問題。  

#### **2.4 實作範例：使用 SVM 進行分類**

```python
from sklearn.svm import SVC

# 建立 SVM 模型（使用 RBF 核函數）
svm = SVC(kernel='rbf', C=1, gamma='scale')
svm.fit(X_train, y_train)

# 預測與評估
y_pred_svm = svm.predict(X_test)
print(f"SVM 模型準確率: {accuracy_score(y_test, y_pred_svm):.2f}")
```

---

### **3. KNN 與 SVM 的比較**

| 特點               | KNN                             | SVM                          |
|--------------------|---------------------------------|------------------------------|
| **模型特性**        | 基於距離的非參數模型             | 基於邊界的參數模型             |
| **計算成本**        | 訓練快但預測時需計算所有樣本距離  | 訓練較慢，但預測快              |
| **處理非線性數據**   | 效果有限                        | 核函數擴展後效果較佳            |
| **適用場景**        | 簡單分類問題                    | 複雜分類問題或高維數據          |

---

## **課後作業**

1. **KNN 實作：**  
   使用 Scikit-learn 提供的數據集（如 Wine 或 Breast Cancer），嘗試調整 \( k \) 值，觀察模型準確率的變化。

2. **SVM 實作：**  
   測試不同的核函數（線性核、多項式核、RBF 核），比較它們對分類效果的影響。

3. 思考與回答：  
   - KNN 為什麼適合用於小規模數據？  
   - SVM 的超參數（例如 \( C \) 和 \( \gamma \)）是如何影響模型的？  
